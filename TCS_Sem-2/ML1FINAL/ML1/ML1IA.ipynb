{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold,cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score,classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APP_ID</th>\n",
       "      <th>CIBIL_SCORE_VALUE</th>\n",
       "      <th>NEW_CUST</th>\n",
       "      <th>CUS_CATGCODE</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>NO_OF_DEPENDENTS</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>EDU_QUA</th>\n",
       "      <th>P_RESTYPE</th>\n",
       "      <th>P_CATEGORY</th>\n",
       "      <th>EMPLOYEE_TYPE</th>\n",
       "      <th>MON_IN_OCC</th>\n",
       "      <th>INCOM_EXP_GMI</th>\n",
       "      <th>LTV</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12345</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767104</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.619077</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12349</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.848949</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12351</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515646</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12353</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.614123</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APP_ID   CIBIL_SCORE_VALUE  NEW_CUST  CUS_CATGCODE    EMPLOYMENT_TYPE   \\\n",
       "0   12345                    0      YES              1                  0   \n",
       "1   12347                    0       NO              1                  1   \n",
       "2   12349                    0      YES              1                  0   \n",
       "3   12351                    2       NO              1                  1   \n",
       "4   12353                    2       NO              1                  1   \n",
       "\n",
       "   AGE  SEX     NO_OF_DEPENDENTS    MARITAL    EDU_QUA    P_RESTYPE   \\\n",
       "0   31      F                   3          0         0             1   \n",
       "1   40      F                   2          1         1             0   \n",
       "2   27      F                   3          0         0             1   \n",
       "3   33      M                   2          0         1             0   \n",
       "4   29      F                   1          0         1             1   \n",
       "\n",
       "    P_CATEGORY    EMPLOYEE_TYPE     MON_IN_OCC    INCOM_EXP_GMI        LTV  \\\n",
       "0             4                2             36                0  0.767104   \n",
       "1             1                1             12                2  0.619077   \n",
       "2             2                2             72                0  0.848949   \n",
       "3             2                1            120                1  0.515646   \n",
       "4             2                1             24                2  0.614123   \n",
       "\n",
       "    TENURE   STATUS  \n",
       "0        12       0  \n",
       "1        24       0  \n",
       "2        36       0  \n",
       "3        12       0  \n",
       "4        24       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"/home/user7/Downloads/ML1/MSDS.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset shape: (13299, 18)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop rows with any null values\n",
    "df = df.dropna()\n",
    "\n",
    "# Print the number of rows and columns in the cleaned dataset\n",
    "print(\"Cleaned dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating features and label\n",
    "features = df.drop(['STATUS'],axis=1)\n",
    "labels = df['STATUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables\n",
    "features = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APP_ID</th>\n",
       "      <th>CIBIL_SCORE_VALUE</th>\n",
       "      <th>CUS_CATGCODE</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NO_OF_DEPENDENTS</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>EDU_QUA</th>\n",
       "      <th>P_RESTYPE</th>\n",
       "      <th>P_CATEGORY</th>\n",
       "      <th>EMPLOYEE_TYPE</th>\n",
       "      <th>MON_IN_OCC</th>\n",
       "      <th>INCOM_EXP_GMI</th>\n",
       "      <th>LTV</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>NEW_CUST_NO</th>\n",
       "      <th>NEW_CUST_YES</th>\n",
       "      <th>SEX  _F</th>\n",
       "      <th>SEX  _M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12345</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767104</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.619077</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12349</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.848949</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12351</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515646</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12353</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.614123</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APP_ID   CIBIL_SCORE_VALUE   CUS_CATGCODE    EMPLOYMENT_TYPE   AGE  \\\n",
       "0   12345                    0              1                  0   31   \n",
       "1   12347                    0              1                  1   40   \n",
       "2   12349                    0              1                  0   27   \n",
       "3   12351                    2              1                  1   33   \n",
       "4   12353                    2              1                  1   29   \n",
       "\n",
       "    NO_OF_DEPENDENTS    MARITAL    EDU_QUA    P_RESTYPE    P_CATEGORY   \\\n",
       "0                   3          0         0             1             4   \n",
       "1                   2          1         1             0             1   \n",
       "2                   3          0         0             1             2   \n",
       "3                   2          0         1             0             2   \n",
       "4                   1          0         1             1             2   \n",
       "\n",
       "    EMPLOYEE_TYPE     MON_IN_OCC    INCOM_EXP_GMI        LTV   TENURE   \\\n",
       "0                2             36                0  0.767104        12   \n",
       "1                1             12                2  0.619077        24   \n",
       "2                2             72                0  0.848949        36   \n",
       "3                1            120                1  0.515646        12   \n",
       "4                1             24                2  0.614123        24   \n",
       "\n",
       "   NEW_CUST_NO  NEW_CUST_YES   SEX  _F   SEX  _M  \n",
       "0            0             1         1         0  \n",
       "1            1             0         1         0  \n",
       "2            0             1         1         0  \n",
       "3            1             0         0         1  \n",
       "4            1             0         1         0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train, test split\n",
    "X_train,X_test, y_train,y_test = train_test_split(features, labels, test_size=0.2, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sclaing the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.18480332,  1.10947828,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743],\n",
       "       [ 0.23436606, -0.04480877,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743],\n",
       "       [-0.12348244, -1.19909583,  0.31852752, ...,  1.43797163,\n",
       "         0.33160743, -0.33160743],\n",
       "       ...,\n",
       "       [ 1.54604251, -0.04480877,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743],\n",
       "       [-0.49385042, -1.19909583,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743],\n",
       "       [ 1.58933905,  1.10947828,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.62504414,  1.10947828,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743],\n",
       "       [ 1.63915615,  1.10947828,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743],\n",
       "       [ 0.98292669, -0.04480877,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743],\n",
       "       ...,\n",
       "       [-0.27606361,  1.10947828,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743],\n",
       "       [ 1.39789532,  1.10947828,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743],\n",
       "       [-1.33787209, -0.04480877,  0.31852752, ..., -0.69542401,\n",
       "         0.33160743, -0.33160743]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "# preparing models\n",
    "models = []\n",
    "models.append((\"Logistic Regression\", LogisticRegression()))\n",
    "models.append(('Decision Tree', DecisionTreeClassifier()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append((\"Gradient Boosting\", GradientBoostingClassifier()))\n",
    "models.append((\"AdaBoost\", AdaBoostClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.623133 (0.011420)\n",
      "Decision Tree: 0.567635 (0.018926)\n",
      "Random Forest: 0.659976 (0.013963)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7fe685483c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    448\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 256\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 264\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 264\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    504\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             sample_weight_val, begin_at_stage, monitor)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    561\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                 random_state, X_csc, X_csr)\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 215\u001b[0;31m                      check_input=False)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=15, shuffle=True,random_state=random_state)\n",
    "    cv_results = cross_val_score(model, features, labels, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3d7e887780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot for Comparison of Different Models\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparison of Different Models')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls1 = RandomForestClassifier(random_state=7)\n",
    "cls1.fit(X_train,y_train)\n",
    "y_pred = cls1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6530075187969925\n",
      "[[1381  290]\n",
      " [ 633  356]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75      1671\n",
      "           1       0.55      0.36      0.44       989\n",
      "\n",
      "    accuracy                           0.65      2660\n",
      "   macro avg       0.62      0.59      0.59      2660\n",
      "weighted avg       0.64      0.65      0.63      2660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls2 = GradientBoostingClassifier(random_state=7)\n",
    "cls2.fit(X_train,y_train)\n",
    "y_pred = cls2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6729323308270677\n",
      "[[1407  264]\n",
      " [ 606  383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1671\n",
      "           1       0.59      0.39      0.47       989\n",
      "\n",
      "    accuracy                           0.67      2660\n",
      "   macro avg       0.65      0.61      0.62      2660\n",
      "weighted avg       0.66      0.67      0.65      2660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
